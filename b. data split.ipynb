{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting\n",
    "The data splitting process uses the scikit-learn package due to its user-friendly interface and support for stratified splitting, which helps maintain label distribution across the training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling file and directory\n",
    "import os\n",
    "import shutil\n",
    "# handle the data info\n",
    "import pandas as pd\n",
    "# handle the data splitting\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"./dataset/prepared_dataset\"\n",
    "destination_path = \"./dataset/splited_dataset\"\n",
    "labels = os.listdir(dataset_path)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe\n",
    "the dataframe is made to store the image path and it's label information. the dataframe is used to make the splitting process easy because the format is suitable for scikit-learn needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/prepared_dataset\\cardboard\\cardboard...</td>\n",
       "      <td>cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/prepared_dataset\\cardboard\\cardboard...</td>\n",
       "      <td>cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/prepared_dataset\\cardboard\\cardboard...</td>\n",
       "      <td>cardboard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path      label\n",
       "0  ./dataset/prepared_dataset\\cardboard\\cardboard...  cardboard\n",
       "1  ./dataset/prepared_dataset\\cardboard\\cardboard...  cardboard\n",
       "2  ./dataset/prepared_dataset\\cardboard\\cardboard...  cardboard"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate the dataframe\n",
    "dataset = pd.DataFrame(columns=[\"path\", \"label\"])\n",
    "# populate the dataframe\n",
    "for label in labels:\n",
    "    # get all the files in the directory\n",
    "    files = os.listdir(f\"{dataset_path}/{label}\")\n",
    "    for file in files:\n",
    "        # add the file path and the label to the dataframe\n",
    "        dataset.loc[len(dataset)] = [os.path.join(dataset_path, label, file), label]\n",
    "# check the dataframe\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset\n",
    "Split the dataset using stratified method to ensure it's label distribution. the ratio used is 20% for the test size, this ratio is considering the small amount of dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, img_test, label_train, label_test = train_test_split(dataset.path,\n",
    "                                                                dataset.label,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=191502,\n",
    "                                                                stratify=dataset.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the split result\n",
    "Transform the split result into a dataframe to make the handling easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.DataFrame({\"path\": img_train, \"label\": label_train}).reset_index(drop=True)\n",
    "testset = pd.DataFrame({\"path\": img_test, \"label\": label_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset count: 2021 (80%)\n",
      "testset count: 506 (20%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"trainset count: {trainset.shape[0]} ({round(trainset.shape[0]/len(dataset)*100)}%)\",\n",
    "    f\"testset count: {testset.shape[0]} ({round(testset.shape[0]/len(dataset)*100)}%)\",\n",
    "    sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the splitted directory\n",
    "the directory will be used for storing the splitted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_type in ['train', 'test']:\n",
    "    for label in labels:\n",
    "        os.makedirs(f\"{destination_path}/{data_type}/{label}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the spliited directory\n",
    "Copy the dataset into their place on the new splitted directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the trainset to the destination directory\n",
    "for i, row in trainset.iterrows():\n",
    "    shutil.copy(row.path, f\"{destination_path}/train/{row.label}\")\n",
    "# copy the testset to the destination directory\n",
    "for i, row in testset.iterrows():\n",
    "    shutil.copy(row.path, f\"{destination_path}/test/{row.label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv_3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
